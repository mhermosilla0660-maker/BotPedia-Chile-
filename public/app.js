// public/app.js
// Cliente m√≠nimo: negocia WebRTC, recibe texto del modelo por DataChannel
// y lo lee con TTS del tel√©fono (speechSynthesis).

const logEl = (() => {
  const pre = document.createElement("pre");
  pre.style.whiteSpace = "pre-wrap";
  pre.style.fontSize = "12px";
  pre.style.lineHeight = "1.25";
  document.body.appendChild(pre);
  return pre;
})();

function log(...args) {
  const line = args
    .map((a) => (typeof a === "string" ? a : JSON.stringify(a)))
    .join(" ");
  console.log(...args);
  logEl.textContent += line + "\n";
  logEl.scrollTop = logEl.scrollHeight;
}

// ========= TTS (texto -> voz del tel√©fono) =========
function speak(text) {
  try {
    if (!text) return;
    window.speechSynthesis.cancel();
    const u = new SpeechSynthesisUtterance(text);
    // Espa√±ol de Chile (ajusta si prefieres otra)
    u.lang = "es-CL";
    u.rate = 1;
    window.speechSynthesis.speak(u);
  } catch (e) {
    log("‚ö†Ô∏è TTS error:", e);
  }
}

// ========= UI =========
const btnConnect = document.getElementById("btnConnect") || (() => {
  // fallback si tu HTML no tiene id
  const b = document.querySelector("button") || document.createElement("button");
  b.textContent = "Conectar";
  document.body.insertBefore(b, document.body.firstChild);
  return b;
})();

const btnMute = document.getElementById("btnMute");
const btnHang = document.getElementById("btnHang");

let pc = null;
let dc = null;
let connected = false;

btnConnect.addEventListener("click", async () => {
  if (connected) {
    log("Ya est√° conectado.");
    return;
  }
  try {
    await connectRealtime();
  } catch (e) {
    log("‚ùå Error al conectar:", e);
  }
});

if (btnHang) {
  btnHang.addEventListener("click", () => {
    if (pc) pc.close();
    pc = null;
    connected = false;
    log("‚òéÔ∏è Colgado.");
  });
}

async function connectRealtime() {
  log("üåê Iniciando negociaci√≥n‚Ä¶");

  // 1) PeerConnection
  pc = new RTCPeerConnection({
    iceServers: [{ urls: "stun:stun.l.google.com:19302" }],
  });

  // (Opcional) crea un MediaStream de salida por si en el futuro recibes audio remoto
  const remoteAudio = document.getElementById("remoteAudio") || (() => {
    const a = document.createElement("audio");
    a.autoplay = true;
    a.playsInline = true;
    a.id = "remoteAudio";
    document.body.appendChild(a);
    return a;
  })();

  pc.ontrack = (ev) => {
    // Si el modelo enviara audio remoto, sonar√≠a aqu√≠
    remoteAudio.srcObject = ev.streams[0];
    log("üîä Audio remoto conectado");
  };

  // 2) Canal de datos para eventos Realtime
  dc = pc.createDataChannel("oai-events");
  dc.onopen = () => {
    log("üì® DataChannel abierto");
    // Al abrir, configuramos la sesi√≥n y forzamos un primer turno de texto
    bootstrapSessionAndAsk();
  };
  dc.onmessage = (ev) => handleRealtimeMessage(ev.data);

  // 3) Oferta SDP local
  const offer = await pc.createOffer({
    offerToReceiveAudio: true,
    offerToReceiveVideo: false,
  });
  await pc.setLocalDescription(offer);

  // 4) Enviar oferta al backend /session (que la reenv√≠a a OpenAI)
  const resp = await fetch("/session", {
    method: "POST",
    headers: { "Content-Type": "application/sdp" },
    body: offer.sdp,
  });
  const answerSdp = await resp.text();
  if (!resp.ok) {
    log("‚ùå /session status:", resp.status);
    log(answerSdp);
    throw new Error("Fall√≥ negociaci√≥n con /session");
  }

  await pc.setRemoteDescription({ type: "answer", sdp: answerSdp });
  connected = true;
  log("‚úÖ Conectado a modelo Realtime.");
}

// Configura la sesi√≥n para TEXTO y env√≠a un primer mensaje para que hable
function bootstrapSessionAndAsk() {
  if (!dc || dc.readyState !== "open") return;

  // 1) Asegura que el modelo responder√° en TEXTO (no pedimos 'audio')
  const sessionUpdate = {
    type: "session.update",
    session: {
      // No forzamos voice aqu√≠. Dejamos SOLO texto.
      // Si m√°s adelante quieres audio del modelo: response.modalities = ["audio"]
      // y ajustas el server/app acorde.
      input_audio_format: { type: "input_text" },
      turn_detection: null,
    },
  };
  dc.send(JSON.stringify(sessionUpdate));
  log("üõ†Ô∏è session.update enviado");

  // 2) Primer turno: pedimos que se presente y confirme conexi√≥n
  const saludo =
    "Pres√©ntate brevemente como BotPedia Chile. Di 'listo, conectado' y luego preg√∫ntame en qu√© caso cl√≠nico pedi√°trico quieres practicar.";

  // Crea un item de texto
  dc.send(
    JSON.stringify({
      type: "conversation.item.create",
      item: { type: "input_text", text: saludo, role: "user" },
    })
  );

  // Pide respuesta
  dc.send(JSON.stringify({ type: "response.create" }));
  log("‚û°Ô∏è response.create enviado");
}

// Maneja todos los eventos del Realtime que llegan por DataChannel
function handleRealtimeMessage(raw) {
  let msg;
  try {
    msg = JSON.parse(raw);
  } catch {
    log("üì©", raw);
    return;
  }

  // Descomenta si quieres ver TODO:
  // log("DC:", msg);

  switch (msg.type) {
    case "session.created":
      log("üÜó session.created");
      break;

    case "response.created":
      // comenz√≥ a generar
      break;

    case "response.delta":
      // Algunas versiones env√≠an deltas; si viene texto incremental, lo acumulas aqu√≠ si quieres.
      break;

    case "response.completed":
    case "response.done": {
      // En la mayor√≠a de versiones, aqu√≠ viene el texto final
      const text =
        msg.response?.output_text?.join(" ") ||
        msg.output_text?.join?.(" ") ||
        extractAnyText(msg) ||
        "";
      if (text) {
        log("üó£Ô∏è", text);
        speak(text); // TTS del tel√©fono
      }
      break;
    }

    case "conversation.item.created": {
      // A veces el mensaje viene tambi√©n aqu√≠:
      const t = extractAnyText(msg) || "";
      if (t) {
        log("üó£Ô∏è", t);
        speak(t);
      }
      break;
    }

    case "error":
      log("‚ùå DC error:", msg);
      break;

    default:
      // Otros eventos
      // log("‚ÑπÔ∏è", msg.type);
      break;
  }
}

// Intenta encontrar texto en distintas formas (defensivo ante cambios de API)
function extractAnyText(msg) {
  try {
    // 1) output_text directo
    if (msg.response?.output_text?.length)
      return msg.response.output_text.join(" ");

    // 2) item.message.content[*].text u otras variantes
    const content =
      msg.item?.content || msg.response?.content || msg.delta?.content || [];
    const parts = [];
    for (const c of content) {
      if (typeof c === "string") parts.push(c);
      if (c?.text) parts.push(c.text);
      if (c?.delta) parts.push(c.delta);
      if (c?.type?.includes?.("text") && c?.content) parts.push(c.content);
    }
    return parts.join(" ");
  } catch {
    return "";
  }
}
