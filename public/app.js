(function () {
  const logBox = document.getElementById("log");
  const connectBtn = document.getElementById("connectBtn");
  const muteBtn = document.getElementById("muteBtn");
  const hangupBtn = document.getElementById("hangupBtn");

  let pc, localStream, dc;

  const log = (m) => {
    const t = new Date().toLocaleTimeString();
    logBox.textContent += `[${t}] ${m}\n`;
    logBox.scrollTop = logBox.scrollHeight;
  };

  window.addEventListener("error", e => log(`JS error: ${e.message}`));
  window.addEventListener("unhandledrejection", e => log(`Promise error: ${e.reason}`));

  connectBtn.addEventListener("click", async () => {
    try {
      // 1) RTCPeerConnection
      pc = new RTCPeerConnection({
        iceServers: [{ urls: "stun:stun.l.google.com:19302" }],
      });

      // 2) Canal de datos para eventos Realtime
      dc = pc.createDataChannel("oai-events");
      dc.onopen = () => {
        log("ðŸ›°ï¸ DataChannel abierto, pidiendo respuesta de audioâ€¦");
        // Envia el comando para que el modelo HABLE en espaÃ±ol
        const msg = {
          type: "response.create",
          response: {
            modalities: ["audio"],      // queremos audio de salida
            instructions:
              "Habla en espaÃ±ol chileno, claro y breve. " +
              "Eres BotPedia Chile, avatar de simulaciÃ³n educativa. " +
              "Si detectas audio de usuario, salÃºdale y pÃ­dele que te cuente el caso.",
            voice: "alloy"              // voz del modelo (si tu cuenta la soporta)
          }
        };
        dc.send(JSON.stringify(msg));
      };
      dc.onmessage = (ev) => log(`ðŸ“© DC: ${ev.data}`);
      dc.onerror = (ev) => log(`âŒ DC error: ${ev.message || ev}`);

      // 3) Audio local (micrÃ³fono) -> envÃ­o al modelo
      localStream = await navigator.mediaDevices.getUserMedia({ audio: true });
      localStream.getTracks().forEach(t => pc.addTrack(t, localStream));

      // 4) Audio remoto -> reproducir
      pc.ontrack = (ev) => {
        const audio = document.createElement("audio");
        audio.autoplay = true;
        audio.srcObject = ev.streams[0];
        document.body.appendChild(audio);
        log("ðŸ”Š Audio remoto conectado");
      };

      // Recibir y enviar audio (full duplex)
      pc.addTransceiver("audio", { direction: "sendrecv" });

      // 5) Oferta SDP -> backend -> OpenAI
      const offer = await pc.createOffer();
      await pc.setLocalDescription(offer);

      log("ðŸŒ Enviando SDP offer a /sessionâ€¦");
      const r = await fetch("/session", {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({ sdp: offer.sdp }),
      });
      const data = await r.json();
      log(`â†©ï¸ /session status: ${r.status}`);

      if (!data?.sdp) throw new Error("No llegÃ³ SDP desde el servidor");
      await pc.setRemoteDescription({ type: "answer", sdp: data.sdp });
      log("âœ… Conectado a modelo Realtime. Â¡Habla cerca del micrÃ³fono!");

    } catch (err) {
      log(`âŒ Error al conectar: ${err.message}`);
    }
  });

  muteBtn.addEventListener("click", () => {
    if (!localStream) return;
    const t = localStream.getTracks()[0];
    t.enabled = !t.enabled;
    log(t.enabled ? "ðŸ”Š MicrÃ³fono ACTIVADO" : "ðŸ”‡ MicrÃ³fono SILENCIADO");
  });

  hangupBtn.addEventListener("click", () => {
    if (pc) {
      pc.getSenders().forEach(s => s.track && s.track.stop());
      pc.close();
      pc = null;
      log("ðŸ“´ Llamada colgada");
    }
  });
})();
